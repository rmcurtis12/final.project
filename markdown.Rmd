---
title: "Final Project"
author: "Takashi Takizawa"
date: "2017/4/8"
output: html_document
---

#Table of contents
1. Data cleaning & preparation
1.1 Step logit
1.2 Random forest on variables ID'd by step logit
2. Run ML models
3. Generate predictions for all models
7. Create Ensemble Model

#1. Data cleaning & preparation 

Import library
```{r}
rm(list = ls())
#install.packages("party")
# install.packages("beepr")
# install.packages("caret")
# install.packages("ada")
#install.packages("e1071")
#install.packages("multcomp")
#install.packages("party")

library(multcomp)
library(party)
library(plyr)
library(dplyr)
library(class)
library(gmodels)
library(stats)
library(magrittr)
library(beepr)
library(caret)
library(kernlab)
library(neuralnet)
library(randomForest)
library(ada)
library(C50)

```

Aux functions
```{r}

midbeep <- function() {beepr::beep("coin")}
endbeep <- function() {beepr::beep("complete")}
```

Data cleaning
```{r setup, include=FALSE}
speed <- read.csv("Speed Dating Data.csv")
speed$condtn <- as.factor(speed$condtn)
speed$gender <- as.factor(speed$gender)
speed$match <- as.factor(speed$match)
speed$field_cd <- as.factor(speed$field_cd)
levels(speed$field_cd) <- c("Law","Math","SocScie/Psych", "MedSci", "Engineering", "English", "History", "Business", "Education", "Bio","SocialWork","Undergrad", "PoliSci", "Film","FineArts","Lang","Architecture","Other")
speed$race <- as.factor(speed$race)
speed$goal <- as.factor(speed$goal)
levels(speed$goal) <- c("FunNightOut", "MeetNewPpl", "GetADate","SRSRelationship", "ToSayIDidIt","Other")

speed$date <- as.factor(speed$date)
#Don't convert to date as character
#levels(speed$date) <- c("SVRL/Week","2/Week","1/Week","2/Month", "1/Month", "SVRL/Year", "AlmostNever")

speed$go_out <- as.factor(speed$go_out)
levels(speed$go_out) <- c("SVRL/Week","2/Week","1/Week","2/Month", "1/Month", "SVRL/Year", "AlmostNever")
speed$career_c <-as.factor(speed$career_c)
levels(speed$career_c) <- c("Lawyer","Academic/Research","Psychologist","DocMed", "Engineer", "Entertainment", "Banking/Consulting", "RealEstate","IntlAffairs","Undecided","SocialWork","SpeechPath","Politics", "ProSports", "Other", "Journalism", "Architecture")
speed$race_o <-as.factor(speed$race_o) 
#speed$dec_o <- as.factor(speed$dec_o)
#speed$samerace <- as.factor(speed$samerace)

sd2 <- speed
sd2 <- sd2[ , -1] #IID  
sd2 <- sd2[, -1] #ID  
sd2 <- sd2[, -2] #IDG
sd2 <- sd2[, -3] #Wave
sd2 <- sd2[, -3] #Round
sd2 <- sd2[, -3] #Position
sd2 <- sd2[, -3] #Postion1
sd2 <- sd2[, -4] #Partner 
sd2 <- sd2[, -4] #PID
sd2 <- sd2[, -26]#Field
sd2 <- sd2[, -(27:29)]#Academics
sd2 <- sd2[,-(30:32)]#Socioeconomic 
sd2 <- sd2[,-33]#Career
sd2 <- sd2[,-(59:64)]#What others look for
sd2 <- sd2[,-(70:74)]#Others perception
sd2 <- sd2[,-(81:92)]#Data gathered after intitial
sd2 <- sd2[,(1:79)]
sd2 <- sd2[,-(70:79)] #Removes Post First Date
sd2 <- sd2[,-52]#exclude expnum

# sd2$mn_sat <- speed$mn_sat
# sd2$mn_sat[sd2$mn_sat==""]<-NA

sdrandom <- sd2[sample(nrow(sd2), nrow(sd2)),] #Get a random sample since the data is organized by participant

sdclean <- na.omit(sdrandom) #Remove rows with NA values to create a "clean" set
```


Create new variables to show gaps between objects and partners
```{r}
normalize<-function(x){
  return((x-min(x))/(max(x)-min(x)))}

#age difference
# sdclean$age_dif<-sdclean$age - sdclean$age_o

# #intelligence difference between sat score and partner's preference
# x<-data.frame(lapply(sdclean[18], normalize))
# sdclean$mn_sat<-as.numeric(sdclean$mn_sat)
# y<-as.data.frame(lapply(sdclean[69], normalize))
# z<- x-y

#partner's preference and actual rating
sdclean$att_dif<-sdclean$pf_o_att - sdclean$attr1_1
sdclean$sinc_dif<-sdclean$pf_o_sin - sdclean$sinc1_1
sdclean$intel_dif<-sdclean$pf_o_int - sdclean$intel1_1
sdclean$fun_dif<-sdclean$pf_o_fun - sdclean$fun1_1
sdclean$amb_dif<-sdclean$pf_o_amb - sdclean$amb1_1
sdclean$shar_dif<-sdclean$pf_o_sha - sdclean$shar1_1

```

Normarize variables
```{r}
#age difference
# a<-data.frame(lapply(sdclean[69], normalize))
# sdclean$age_dif_norm<-a$age_dif

#intelligence difference
# b<-as.data.frame(lapply(z[1], normalize))
# sdclean$intel_dif<-b$intel_o

#date frequency
# sdclean$date<-as.numeric(sdclean$date)
# c<-data.frame(lapply(sdclean[31], normalize))
# sdclean$date_norm<-c$date

#partner's preference and actual rating
d<-data.frame(lapply(sdclean[69], normalize))
sdclean$att_dif_norm<-d$att_dif

e<-data.frame(lapply(sdclean[70], normalize))
sdclean$sinc_dif_norm<-e$sinc_dif

f<-data.frame(lapply(sdclean[71], normalize))
sdclean$intel_dif_norm<-f$intel_dif

g<-data.frame(lapply(sdclean[72], normalize))
sdclean$fun_dif_norm<-g$fun_dif

h<-data.frame(lapply(sdclean[73], normalize))
sdclean$amb_dif_norm<-h$amb_dif

i<-data.frame(lapply(sdclean[74], normalize))
sdclean$shar_dif_norm<-i$shar_dif

#rating of partners by objects (inter-correlation)
# j<-data.frame(lapply(sdclean[5], normalize))
# sdclean$int_corr_norm<-j$int_corr

sdclean2 <- as.data.frame(model.matrix(~ ., sdclean))

sdclean2$`(Intercept)` <- NULL

str(sdclean2)

sdclean2$field_cdSocSciePsych <- sdclean2$`field_cdSocScie/Psych`
sdclean2$go_out2Week <- sdclean2$`go_out2/Week`
sdclean2$go_out1Week <- sdclean2$`go_out1/Week`
sdclean2$go_out2Month <- sdclean2$`go_out2/Month`
sdclean2$go_out1Month <- sdclean2$`go_out1/Month`
sdclean2$go_outSVRLYear <- sdclean2$`go_outSVRL/Year`
sdclean2$career_cAcademicResearch <- sdclean2$`career_cAcademic/Research`
sdclean2$career_cBankingConsulting <- sdclean2$`career_cBanking/Consulting`

sdclean2$`field_cdSocScie/Psych` <- NULL
sdclean2$`go_out2/Week` <- NULL
sdclean2$`go_out1/Week` <- NULL
sdclean2$`go_out2/Month` <- NULL
sdclean2$`go_out1/Month` <- NULL
sdclean2$`go_outSVRL/Year` <- NULL
sdclean2$`career_cAcademic/Research` <- NULL
sdclean2$`career_cBanking/Consulting` <- NULL
save(sdclean2, file = "sdclean2")

```

#1.1 Step Logit to identify significant prediction variables
```{r}
#Working with sdclean data, not sdfinal
##Make train and test data

load(file = "sdclean2")

set.seed(628)
train_data_sdclean<-sdclean2[1:4500,]
test_data_sdclean<-sdclean2[4501:6499,]

#Make labels for train and test data
train_label_sdclean<-sdclean2$match1[1:4500]
test_label_sdclean<-sdclean2$match1[4501:6499]

log_step_f <- colnames(sdclean2) %>% 
    {paste(.[! . %in% "match1"], collapse = " + ")} %>% 
    paste("match1 ~ ", .) %>% 
    as.formula()

log_step_f

log_model_step <- glm(match1 ~ 1, data = train_data_sdclean, family = binomial)
log_model_step <- step(log_model_step, scope = (log_step_f), direction = "forward")
  
summary(log_model_step)
save(log_model_step,file = "log_model_step.txt")

#sig_var <- c("prob_o","pf_o_sha","gender","met_o","exercise","exphappy","yoga","attr1_1","pf_o_sin","art","gaming","intel2_1","attr2_1","clubbing","dining","intel3_1","fun_o","movies","tv")

sig_var <- c("prob_o","pf_o_sha","gender1","race2","pf_o_sin","attr1_1","exphappy","met_o","sports","race_o4","career_cPolitics","field_cdBusiness","gaming","dining","art","movies","attr_o")
```

#1.2 Random forest on significant variables
```{r}
#create the formula for random forest "match ~ blah + blah + blah..."
sig_var_f <- sig_var %>% 
    {paste(.[! . %in% "match1"], collapse = " + ")} %>% 
    paste("match1 ~ ", .) %>% 
    as.formula()

sig_var_f

#run the RANdom FORest on the SIGnificant VARiables
set.seed(628)
ran_for_sig_var <- randomForest(formula = sig_var_f, data = train_data_sdclean, importance=TRUE)

plot(ran_for_sig_var)

summary(ran_for_sig_var)

varImpPlot(ran_for_sig_var,
           sort = T,
           main="Variable Importance")

ran_for_sig_var_pred <- predict(ran_for_sig_var,test_data_sdclean) %>% {ifelse(. > 0.5, "1", "0")} %>% as.numeric()

#summary(ran_for_pred)
#summary(test_label_sdclean)

confusionMatrix(data=ran_for_sig_var_pred,reference=test_data_sdclean$match1)

```


#2. Run the models
```{r}
#Log model
set.seed(628)
train_data_sdclean$match2 <- train_data_sdclean$match1 - 1
log_f <- sig_var %>% 
    {paste(.[! . %in% "match1"], collapse = " + ")} %>% 
    paste("match2 ~ ", .) %>% 
    as.formula()
log_model <- glm(formula = log_f, data = train_data_sdclean, family = binomial)

#Develop KNN Models
set.seed(628)
knn_pred_21<-knn(train=train_data_sdclean, test=test_data_sdclean, cl=train_label_sdclean, k=21)
set.seed(628)
knn_pred_7<-knn(train=train_data_sdclean, test=test_data_sdclean, cl=train_label_sdclean, k=7)

#develop SVM models
set.seed(628)
library(e1071)
svm_model_lin <- svm(formula = sig_var_f, data = train_data_sdclean, kernel = "linear")

set.seed(628)
svm_model_rad <- svm(formula = sig_var_f, data = train_data_sdclean, kernel = "radial")

#develop random forest model
set.seed(628)
random_forest_model <- randomForest(formula = sig_var_f, data = train_data_sdclean)

#develop ctree model
set.seed(628)
library(partykit)
ctree_model <- ctree(formula = sig_var_f, data = train_data_sdclean, control = ctree_control(mincriterion = .90))

#develop boosted tree
#C5.0 needs response as a factor
train_data_sdclean$match1 <- as.factor(train_data_sdclean$match1)
boosted_tree_model <- C5.0(formula = sig_var_f, data = train_data_sdclean, trials = 100)
train_data_sdclean$match1 <- as.numeric(train_data_sdclean$match1)

#develop ANN model
library(neuralnet)
set.seed(628)
#ANN_model <- neuralnet(formula = sig_var_f, data = train_data_sdclean, lifesign = "full", hidden = 20)


```

#3. Make Predictions from Test Data
```{r}
log_pred <- predict(log_model, test_data_sdclean, type = "response") %>% {ifelse(. > 0.5, "1", "0")} %>% as.numeric()

svm_pred_lin <- predict(svm_model_lin, test_data_sdclean) %>% {ifelse(. > 0.5, "1", "0")} %>% as.numeric()

svm_pred_rad <- predict(svm_model_rad, test_data_sdclean) %>% {ifelse(. > 0.5, "1", "0")} %>% as.numeric()


ran_for_pred <- predict(random_forest_model, test_data_sdclean) %>% {ifelse(. > 0.5, "1", "0")} %>% as.numeric()

ctree_pred <- predict(ctree_model, test_data_sdclean) %>% {ifelse(. > 0.5, "1", "0")} %>% as.numeric()

boosted_tree_pred <- predict(boosted_tree_model, test_data_sdclean)

#ann_pred <- predict(ANN_model, test_data_sdclean)


```

#4. Determine accuracy
```{r}
accuracy <- function(predicted, trueval, model, hideoutput = F) {
  stopifnot(length(predicted) == length(trueval))
  result <- sum(predicted == trueval) / length(predicted)
  if (!hideoutput) {cat("Model:", model, "had", result, "accuracy\n")}
  return(result)
}

a0 = accuracy(log_pred, test_data_sdclean$match1, "Logit", TRUE)
a1 = accuracy(knn_pred_21, test_data_sdclean$match1, "KNN 21", TRUE)
a2 = accuracy(knn_pred_7, test_data_sdclean$match1, "KNN 7", TRUE)
a3 = accuracy(svm_pred_lin, test_data_sdclean$match1, "SVM (cartesian)", TRUE)
a4 = accuracy(svm_pred_rad, test_data_sdclean$match1, "SVM (polar)", TRUE)
a5 = accuracy(ran_for_pred, test_data_sdclean$match1, "Random Forest", TRUE)
a6 = accuracy(ctree_pred, test_data_sdclean$match1, "Ctree", TRUE)
a7 = accuracy(boosted_tree_pred, test_data_sdclean$match1, "Boosted Tree", TRUE)
#a8 = accuracy(ann_pred, test_data_sdclean$match1, "Neural Net 50 (!) Hidden Node", TRUE)

acc_predictions = c(a0,a1,a2,a3,a4,a5,a6,a7)
names = c("Logit", "kNN 21", "kNN 7", "SVM (cartesian)","SVM (polar)","Random Forest","CTree","Boosted Tree")

acc_mat <- data.frame(ModelName = names, accuracy = acc_predictions) %>% print
```

```{r}
dotchart(acc_predictions, labels = names, main = "Accuracy of the models", xlab = "Accuracy")
```


#7. Create Ensemble Model

```{r}

# Convert all of the feature data to factors....
ConvertToYesNo <- function(myprediction) {
  result <- myprediction %>% as.factor()
  levels(result) <- c("no", "yes")
  result
}

library(magrittr)
library(dplyr)

# Convert each set of predictions to factors
log_pred %<>% ConvertToYesNo()
knn_pred_21 %<>% ConvertToYesNo()
knn_pred_7 %<>% ConvertToYesNo()
svm_pred_lin %<>% ConvertToYesNo()
svm_pred_rad %<>% ConvertToYesNo()
ran_for_pred %<>% ConvertToYesNo()
ctree_pred %<>% ConvertToYesNo()
boosted_tree_pred %<>% ConvertToYesNo()

stacked_data <-data.frame(log_pred,knn_pred_21,knn_pred_7,svm_pred_lin,svm_pred_rad,ran_for_pred,ctree_pred,boosted_tree_pred) %>% as.tbl()

summary(model_combined_results)

#generate predictions on train data
log_pred_train <- predict(log_model, train_data_sdclean, type = "response") %>% {ifelse(. > 0.5, "1", "0")} %>% as.numeric()

svm_pred_lin_train <- predict(svm_model_lin, train_data_sdclean) %>% {ifelse(. > 0.5, "1", "0")} %>% as.numeric()

svm_pred_rad_train <- predict(svm_model_rad, train_data_sdclean) %>% {ifelse(. > 0.5, "1", "0")} %>% as.numeric()

knn_pred_21_train <-knn(train=test_data_sdclean, test=train_data_sdclean, cl=test_label_sdclean, k=21)

knn_pred_7_train <-knn(train=test_data_sdclean, test=train_data_sdclean, cl=test_label_sdclean, k=7)

ran_for_pred_train <- predict(random_forest_model, train_data_sdclean) %>% {ifelse(. > 0.5, "1", "0")} %>% as.numeric()

ctree_pred_train <- predict(ctree_model, train_data_sdclean) %>% {ifelse(. > 0.5, "1", "0")} %>% as.numeric()

boosted_tree_pred_train <- predict(boosted_tree_model, train_data_sdclean)

model_combined_results <- data.frame(log_pred_train, svm_pred_lin_train, knn_pred_21_train, knn_pred_7_train, svm_pred_rad_train, ran_for_pred_train, ctree_pred_train, boosted_tree_pred_train) %>% as.tbl()

# Create the model -> Stacking with a Ctree to find out if it helps any!
library(partykit)

names(model_combined_results) <- names(stacked_data)

stacked_model <- ctree(train_data_sdclean$match1 ~ ., data = model_combined_results) %T>% plot
#, controls = ctree_control(mincriterion = 0.99999)

ensemble_pred <- prediction(stacked_model,stacked_train_results)

```


